<h2 id="publications" style="margin: 2px 0px -15px;">Publications</h2>



<div class="publications">
<ol class="bibliography">

<img  src="./assets/img/TransGS.png" alt="" class="teaser"  title="We translate PBR Facial assets to Gaussian Splatting counterpart in seconds, enabling 30fps@1400p rendering on mobile phones." width="70%" height="70%" />
<li>

<div class="pub-row">
  
  <div class="col-sm-9" style="position: relative;padding-right: 0px;padding-left: 0px;">
    <div class="title"><i style="color:#3388A2">Instant Facial Gaussians Translator for Relightable and Interactable Facial Rendering</i></div>
    <div class="author"><Strong>Dafei Qin</Strong>, Hongyang Lin, Qixuan Zhang, Kaichun Qiao, Longwen Zhang, Zijun Zhao, Jun Saito, Jingyi Yu, Lan Xu, Taku Komura</div>
    <div class="periodical"><em>arXiv</em></div>
    <div class="links">
      <a href="https://dafei-qin.github.io/TransGS.github.io/" class="link" role="link" target="_blank" style="font-size:16px;"><u>Project Page</u></a>
    </div>
  </div>
</div>
</li>

<img  src="./assets/img/Media2Face.jpg" alt="" class="teaser"  title="We generate 3D talking face animation with head motions from audio, with rich controls from styles, text, images and etc." width="70%" height="70%" />
<li>

<div class="pub-row">
  
  <div class="col-sm-9" style="position: relative;padding-right: 0px;padding-left: 0px;">
    <div class="title"><i style="color:#3388A2">Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance </i></div>
    <div class="author">Qingcheng Zhao, Pengyu Long, Qixuan Zhang, <Strong>Dafei Qin</Strong>, Han Liang, Longwen Zhang, Yingliang Zhang, Jingyi Yu, Lan Xu</div>
    <div class="periodical"><em>ACM SIGGRAPH 2024 (Conference Track)</em></div>
    <div class="links">
      <a href="https://huggingface.co/papers/2401.15687" class="link" role="link" target="_blank" style="font-size:16px;"><u>Project Page</u></a>
    </div>
  </div>
</div>
</li>


<img  src="./assets/img/NFR.jpg" alt="" class="teaser"  title="Top: Given an unrigged facial mesh with an unknown expression and identity in an arbitrary triangulation (yellow), NFR can transfer the expression to unrigged facial meshes with arbitrary triangulations (cyan). Bottom: NFR provides an interpretable latent space for user-friendly editing of the retargeted meshes." width="70%" height="70%" />
<li>

<div class="pub-row">
  
  <div class="col-sm-9" style="position: relative;padding-right: 0px;padding-left: 0px;">
    <div class="title"><i style="color:#3388A2">Neural Face Rigging for Animating and Retargeting Facial Meshes in the Wild </i></div>
    <div class="author"><Strong>Dafei Qin</Strong>, Jun Saito, Noam Aigerman, Thibault Groueix, Taku Komura</div>
    <div class="periodical"><em>ACM SIGGRAPH 2023 (Conference Track)</em></div>
    <div class="links">
      <a href="https://dafei-qin.github.io/NFR/" class="link" role="link" target="_blank" style="font-size:16px;"><u>Project Page</u></a>
    </div>
  </div>
</div>
</li>


<img  src="./assets/img/BodyFormer.jpg" alt="" class="teaser"  title="Given an arbitrary input speech, our proposed transformer-based model, BodyFormer, can generate a sequence of vivid 3D body gestures" width="70%" height="70%" />
<li>

<div class="pub-row">



  <div class="col-sm-9" style="position: relative;padding-right: 0px;padding-left: 0px;">
    <div class="title"><i style="color:#3388A2">Bodyformer: Semantics-guided 3D Body Gesture Synthesis With Transformer</i></div>
    <div class="author">Kunkun Pang<sup>*</sup>, <strong>Dafei Qin</strong><sup>*</sup>, Yingruo Fan, Julian Habekost, Takaaki Shiratori, Junichi Yamagishi, Taku Komura</div>
    <div class="periodical"><em>ACM SIGGRAPH 2023 (Journal Track)</em></div>
      <sup>*</sup>Joint First Authors

  </div>
</div>
</li>

<br>

</ol>
</div>